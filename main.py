import io
import numpy as np
import pandas as pd
import altair as alt
import streamlit as st

# ------------------------------
# App Title & Config
# ------------------------------
st.set_page_config(page_title="MBTI Top 10 by Country", layout="wide")
st.title("ğŸ“Š MBTI ìœ í˜•ë³„ ìƒìœ„ 10ê°œ êµ­ê°€ ì‹œê°í™”")
st.caption("ì—…ë¡œë“œí•œ CSVë¥¼ ë°”íƒ•ìœ¼ë¡œ ê° MBTI ìœ í˜• ë¹„ìœ¨ì´ ê°€ì¥ ë†’ì€ êµ­ê°€ TOP 10ì„ Altairë¡œ ì¸í„°ë™í‹°ë¸Œí•˜ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.")

# ------------------------------
# File Upload
# ------------------------------
uploaded = st.file_uploader("CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”", type=["csv"])  # e.g. countriesMBTI_16types.csv
st.write(":information_source: CSVì—ëŠ” êµ­ê°€ëª… ì»¬ëŸ¼ê³¼ 16ê°œ MBTI ì»¬ëŸ¼(INTJ, INTP, â€¦, ESFP)ì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.")

MBTI_TYPES = [
    "INTJ","INTP","ENTJ","ENTP",
    "INFJ","INFP","ENFJ","ENFP",
    "ISTJ","ISFJ","ESTJ","ESFJ",
    "ISTP","ISFP","ESTP","ESFP",
]

@st.cache_data(show_spinner=False)
def load_csv(file) -> pd.DataFrame:
    # Try a couple of encodings just in case
    if file is None:
        return pd.DataFrame()
    content = file.read()
    for enc in ("utf-8", "cp949", "utf-8-sig"):
        try:
            return pd.read_csv(io.BytesIO(content), encoding=enc)
        except Exception:
            continue
    # Fallback: let pandas guess
    return pd.read_csv(io.BytesIO(content))

@st.cache_data(show_spinner=False)
def detect_columns(df: pd.DataFrame):
    # Country-like column
    country_col = None
    for c in df.columns:
        cl = str(c).strip().lower()
        if "country" in cl or "nation" in cl or "êµ­ê°€" in cl or "ë‚˜ë¼" in cl:
            country_col = c
            break
    if country_col is None:
        # fallback: first non-numeric column
        obj_cols = [c for c in df.columns if not pd.api.types.is_numeric_dtype(df[c])]
        country_col = obj_cols[0] if obj_cols else df.columns[0]

    # MBTI columns (case-insensitive exact token match or contains)
    col_map = {}
    for c in df.columns:
        cu = str(c).strip().upper()
        for t in MBTI_TYPES:
            if cu == t or cu.startswith(t) or f" {t}" in cu or t in cu:
                col_map.setdefault(t, c)
                break
    mbti_cols = [col_map[t] for t in MBTI_TYPES if t in col_map]
    return country_col, mbti_cols

@st.cache_data(show_spinner=False)
def clean_and_long(df: pd.DataFrame, country_col: str, mbti_cols: list[str]):
    if df.empty:
        return df, pd.DataFrame(), 1.0

    dfc = df.copy()

    # Strip string whitespace
    for c in dfc.columns:
        if pd.api.types.is_string_dtype(dfc[c]):
            dfc[c] = dfc[c].astype(str).str.strip()

    # Coerce MBTI columns to numeric, remove % and commas
    for c in mbti_cols:
        dfc[c] = (
            dfc[c]
            .astype(str)
            .str.replace("%", "", regex=False)
            .str.replace(",", "", regex=False)
        )
        dfc[c] = pd.to_numeric(dfc[c], errors="coerce")

    # Determine scale (0~1 vs 0~100)
    totals = dfc[mbti_cols].sum(axis=1, skipna=True)
    finite_totals = totals.replace([np.inf, -np.inf], np.nan).dropna()
    expected_scale = 100.0 if (not finite_totals.empty and finite_totals.median() > 1.5) else 1.0

    # If values look like 0~100, convert to 0~1 for consistent formatting
    if expected_scale == 100.0:
        for c in mbti_cols:
            dfc[c] = dfc[c] / 100.0

    # Long-form
    long_df = dfc.melt(
        id_vars=[country_col],
        value_vars=mbti_cols,
        var_name="Type",
        value_name="Value",
    ).dropna(subset=["Value"]) 

    # Normalize type labels to canonical
    # (If original col had like 'INTJ %', map back to 'INTJ')
    canon_map = {}
    for c in mbti_cols:
        cu = str(c).strip().upper()
        key = None
        for t in MBTI_TYPES:
            if cu == t or cu.startswith(t) or t in cu:
                key = t
                break
        canon_map[c] = key if key else c
    long_df["Type"] = long_df["Type"].map(canon_map).fillna(long_df["Type"])    

    # Safety: clip to [0,1]
    long_df["Value"] = long_df["Value"].clip(lower=0, upper=1)

    return dfc, long_df, 1.0  # we standardized to 0~1

@st.cache_data(show_spinner=False)
def topk_by_type(long_df: pd.DataFrame, type_name: str, k: int = 10, country_col: str = "Country"):
    sdf = long_df[long_df["Type"] == type_name].copy()
    sdf = sdf.sort_values("Value", ascending=False).head(k)
    # Keep order in chart
    sdf["Country_ordered"] = pd.Categorical(sdf[country_col], categories=sdf[country_col].tolist(), ordered=True)
    return sdf

@st.cache_data(show_spinner=False)
def topk_all_types(long_df: pd.DataFrame, k: int = 10, country_col: str = "Country"):
    # For each type, take top-k
    out = (
        long_df.sort_values(["Type", "Value"], ascending=[True, False])
        .groupby("Type", group_keys=False)
        .head(k)
        .copy()
    )
    return out

# ------------------------------
# Main UI
# ------------------------------
if uploaded is None:
    st.info("ì˜ˆì‹œ: countriesMBTI_16types.csvì™€ ê°™ì€ í˜•ì‹ì˜ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ê·¸ë˜í”„ê°€ ìƒì„±ë©ë‹ˆë‹¤.")
    st.stop()

raw_df = load_csv(uploaded)
if raw_df.empty:
    st.error("CSVë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹/ì¸ì½”ë”©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

country_col, mbti_cols = detect_columns(raw_df)
if len(mbti_cols) < 16:
    st.warning(f"ê°ì§€ëœ MBTI ì»¬ëŸ¼ ìˆ˜: {len(mbti_cols)} (ì˜ˆìƒ 16) â€” ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

clean_df, long_df, _ = clean_and_long(raw_df, country_col, mbti_cols)

# Sidebar controls
st.sidebar.header("ì„¤ì •")
sel_type = st.sidebar.selectbox("MBTI ìœ í˜• ì„ íƒ", MBTI_TYPES)
top_k = st.sidebar.slider("TOP K", min_value=5, max_value=20, value=10, step=1)

# ------------------------------
# Tab layout
# ------------------------------
tab1, tab2 = st.tabs(["ë‹¨ì¼ ìœ í˜•", "ëª¨ë“  ìœ í˜•(ì†Œë¶„í• )"])

with tab1:
    st.subheader(f"ğŸ” {sel_type} ë¹„ìœ¨ì´ ë†’ì€ êµ­ê°€ TOP {top_k}")
    sdf = topk_by_type(long_df.rename(columns={country_col: "Country"}), sel_type, top_k, country_col="Country")

    if sdf.empty:
        st.warning("ì„ íƒí•œ ìœ í˜• ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    else:
        chart = (
            alt.Chart(sdf)
            .mark_bar()
            .encode(
                x=alt.X("Value:Q", title="ë¹„ìœ¨", axis=alt.Axis(format=".0%")),
                y=alt.Y("Country_ordered:N", title="êµ­ê°€", sort=None),
                tooltip=[
                    alt.Tooltip("Country_ordered:N", title="êµ­ê°€"),
                    alt.Tooltip("Value:Q", title="ë¹„ìœ¨", format=".2%"),
                ],
            )
            .properties(height=420)
            .interactive()
        )
        st.altair_chart(chart, use_container_width=True)

with tab2:
    st.subheader(f"ğŸ§© ëª¨ë“  MBTI ìœ í˜•ë³„ TOP {top_k} êµ­ê°€ (Facet)")
    all_top = topk_all_types(long_df.rename(columns={country_col: "Country"}), top_k, country_col="Country")

    # keep order per facet (Altair sorts within facets by value automatically via '-x')
    chart_all = (
        alt.Chart(all_top)
        .mark_bar()
        .encode(
            x=alt.X("Value:Q", title="ë¹„ìœ¨", axis=alt.Axis(format=".0%")),
            y=alt.Y("Country:N", title="êµ­ê°€", sort='-x'),
            tooltip=[
                alt.Tooltip("Type:N", title="ìœ í˜•"),
                alt.Tooltip("Country:N", title="êµ­ê°€"),
                alt.Tooltip("Value:Q", title="ë¹„ìœ¨", format=".2%"),
            ],
            column=alt.Column("Type:N", title="ìœ í˜•", sort=MBTI_TYPES),
        )
        .resolve_scale(x='independent', y='independent')
        .properties(height=220)
        .interactive()
    )
    st.altair_chart(chart_all, use_container_width=True)

# ------------------------------
# Data preview & download
# ------------------------------
with st.expander("ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°"):
    st.dataframe(clean_df.head(30))

st.download_button(
    label="ì •ë¦¬ëœ Long-Form ë°ì´í„° ë‹¤ìš´ë¡œë“œ (CSV)",
    data=long_df.to_csv(index=False).encode("utf-8-sig"),
    file_name="mbti_long.csv",
    mime="text/csv",
)

st.caption("â“˜ ê°’ì´ 0~100%ë¡œ ì£¼ì–´ì§„ ê²½ìš° ìë™ìœ¼ë¡œ 0~1 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œí•©ë‹ˆë‹¤. ìŒìˆ˜/100% ì´ˆê³¼ê°’ì€ 0~1 ë²”ìœ„ë¡œ í´ë¦¬í•‘í•©ë‹ˆë‹¤.")
